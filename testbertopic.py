# -*- coding: utf-8 -*-
"""TestBERTopic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IW4COGN5H4z1Jc3q6olsndGn7f404bBA
"""

# pip install sentence-transformers

import torch

if torch.cuda.is_available():
  dev = "cuda:0"
else: 
  dev="cpu"

from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
import re 
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
import os

tf_model = SentenceTransformer('sentence-transformers/gtr-t5-base')

topic_list = ["computers","vehicles","sports","classifieds","politics","religion"]

docs_df = pd.read_csv("./lib/docs_df.csv")

# docs_df

emb_df = pd.read_csv("./lib/emb_df.csv")
emb_df.drop(emb_df.columns[0],axis=1)

# emb_df

# pip install bertopic

from bertopic import BERTopic

# topic_model = BERTopic(language="english", calculate_probabilities=True, verbose=True, nr_topics=6, embedding_model=tf_model)

doc_clean = docs_df.docs_clean.to_numpy()
doc_emb = emb_df.to_numpy()

sub_docs_df_1   = docs_df.docs_clean.loc[docs_df["projected_topic"] == 'computers']
index = docs_df.index[docs_df["projected_topic"] == "computers"]
sub_docs_dmb_1  = emb_df.iloc[index]

# emb_df.iloc[docs_df.index[docs_df["projected_topic"] == "computers"]].to_numpy()

subtopic_model_computers = BERTopic(nr_topics=10)
comp_subtopics, comp_probas = subtopic_model_computers.fit_transform(docs_df.docs_clean.loc[docs_df["projected_topic"] == 'computers'],emb_df.iloc[docs_df.index[docs_df["projected_topic"] == "computers"]].to_numpy())

print(subtopic_model_computers.topics_)

# for topic in topic_list: 
#   globals()['docs_topic_%s' % topic] = docs_df.docs_clean.loc[docs_df["projected_topic"] == topic]
#   globals()['embs_topic_%s' % topic] = emb_df.iloc[docs_df.index[docs_df["projected_topic"] == topic]].to_numpy()

#   globals()['subtopic_model_%s' % topic] = BERTopic()
#   globals()['subtopic_model_%s_topics' % topic], globals()['subtopic_model_%s_probas' % topic] = globals()['subtopic_model_%s' % topic].fit_transform(globals()['docs_topic_%s' % topic], globals()['embs_topic_%s' % topic])

# subtopic_model_computers = BERTopic().fit(docs_topic_computers, embs_topic_computers)


